<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="learnB4SS">
<title>Application to regression IV - Leveling up to hierarchical models • learnB4SS</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Application to regression IV - Leveling up to hierarchical models">
<meta property="og:description" content="learnB4SS">
<meta property="og:image" content="https://learnb4ss.github.io/learnB4SS/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">learnB4SS</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.7.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/contrasts.html">Factors, coding and contrasts</a>
    <a class="dropdown-item" href="../articles/ex_03.html">Application to regression II - Priors and Bayesian updating</a>
    <a class="dropdown-item" href="../articles/ex_06.html">Application to regression III - More Bayesian inference</a>
    <a class="dropdown-item" href="../articles/ex_08.html">Application to regression IV - Leveling up to hierarchical models</a>
    <a class="dropdown-item" href="../articles/faqs.html">FAQs</a>
    <a class="dropdown-item" href="../articles/full-analysis.html">Fully worked-out analysis using a Bayesian regression with brms</a>
    <a class="dropdown-item" href="../articles/glossary.html">Glossary</a>
    <a class="dropdown-item" href="../articles/install-brms.html">How to install brms and dependecies</a>
    <a class="dropdown-item" href="../articles/install-learnb4ss.html">How to install the learnB4SS package</a>
    <a class="dropdown-item" href="../articles/understand-priors.html">Understand and explore priors</a>
    <a class="dropdown-item" href="../articles/why-bayes.html">Why Bayesian?</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/learnB4SS/learnB4SS/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Application to regression IV - Leveling up to hierarchical models</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/learnB4SS/learnB4SS/blob/HEAD/vignettes/ex_08.Rmd" class="external-link"><code>vignettes/ex_08.Rmd</code></a></small>
      <div class="d-none name"><code>ex_08.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Packages</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/learnB4SS/learnB4SS" class="external-link">learnB4SS</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://modelr.tidyverse.org" class="external-link">modelr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/paul-buerkner/brms" class="external-link">brms</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org" class="external-link">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mjskay.github.io/tidybayes/" class="external-link">tidybayes</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/bayestestR/" class="external-link">bayestestR</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">polite</span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="walkthrough">Walkthrough<a class="anchor" aria-label="anchor" href="#walkthrough"></a>
</h2>
<div class="section level3">
<h3 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h3>
<p>Until now, we have only dealt with very simple models, most of which
are just not particularly relevant for what we actually do in our
research, right? So in this section, we will level up. We will add
additional parameters to our regression in the form of fixed effects and
random effect. Sounds much more like the stuff you want to do, right? We
are going to estimate these parameters and specify appropriate priors
for them. After this session you will be much closer to being an
operational Bayesian for your actual research.</p>
</div>
<div class="section level3">
<h3 id="a-simple-model">A simple model<a class="anchor" aria-label="anchor" href="#a-simple-model"></a>
</h3>
<p>Okay let’s think about this. Here is the model that we have so far
looked at alongside its priors:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># specify priors</span></span>
<span><span class="va">priors_simple</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="co"># prior for the Intercept (= the reference level)</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">15</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,</span>
<span>  <span class="co"># prior for the fixed effect coefficient for polite attitude</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">attitudepol</span><span class="op">)</span>,</span>
<span>  <span class="co"># prior for the residual variance</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># specify model</span></span>
<span><span class="va">simple_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html" class="external-link">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span>,  </span>
<span>  data <span class="op">=</span> <span class="va">polite</span>,</span>
<span>  prior <span class="op">=</span> <span class="va">priors_simple</span>,</span>
<span>  family <span class="op">=</span> <span class="va">gaussian</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Brms uses a gaussian link function by default (we made that explicit
above), i.e. we assume that the model residuals are normally
distributed. But is that really the case? We have a measurement that is
bound by 0, because there can’t be negative values for articulation
rate, right? It is likely that articulate rate data are skewed to the
right, because values can vary more toward higher values than toward
lower values. Brms allows us to critically evaluate our model fit by
comparing the model using so-called posterior predictive checks.
Posterior predictive checks are, in simple words, “simulating replicated
data under the fitted model and then comparing these to the observed
data” (<a href="http://www.stat.columbia.edu/~gelman/arm/" class="external-link">Gelman &amp;
Hill 2007: 158</a>). So, you use posterior predictive checks to
investigate whether there are systematic discrepancies between the
observed and simulated data.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># posterior predictive check</span></span>
<span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html" class="external-link">pp_check</a></span><span class="op">(</span><span class="va">simple_model</span>, nsamples <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<p>Looking at the plot, you see a thick dark blue line which is the
data, and bunch of light blue lines which are simulated data based on
your model. The model assumes a normal distribution, so the posterior
draws are much more symmetric than the actual data, thus we notice a
discrepancy between model and data. These situations are common for
measurements that are bound by zero (e.g. duration or response latency).
To account for this, we can use a different link function (specified
with the <code>family</code> argument). A more appropriate model would
use a log normal distribution for articulation rate.</p>
<p>When we change the family, the model will fit the measurement in log
space, so we will have to change the priors. Let’s throw in some numbers
and run a prior_predictive check, i.e. running the model with only the
prior information (<code>sample_prior = "only"</code>). We also need to
specify the <code>lognormal</code> family when running the model.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># specify priors in log space</span></span>
<span><span class="va">priors_simple_log</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="co"># prior for the Intercept (= the reference level)</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,</span>
<span>  <span class="co"># prior for the fixed effect coefficient for polite attitude</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">attitudepol</span><span class="op">)</span>,</span>
<span>  <span class="co"># prior for the residual variance</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># specify model</span></span>
<span><span class="va">simple_model2_prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html" class="external-link">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">articulation_rate</span> <span class="op">~</span> </span>
<span>    <span class="va">attitude</span>,  </span>
<span>    data <span class="op">=</span> <span class="va">polite</span>,</span>
<span>    prior <span class="op">=</span> <span class="va">priors_simple_log</span>,</span>
<span>    <span class="co"># specify that the model should only estimate the posterior based on the information in the prior</span></span>
<span>    sample_prior <span class="op">=</span> <span class="st">"only"</span>,</span>
<span>    <span class="co"># specify lognormal family function</span></span>
<span>    family <span class="op">=</span> <span class="va">lognormal</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># quick and dirty plot on the original scale</span></span>
<span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html" class="external-link">conditional_effects</a></span><span class="op">(</span><span class="va">simple_model2_prior</span><span class="op">)</span></span></code></pre></div>
<p>Well, our priors are very weakly informative and cover more than what
we consider a possible range for articulation rate. However it
constraints the parameter space substantially already. Good enough.</p>
<p>Let’s refit the model and specify the <code>lognormal</code>
family.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># specify model</span></span>
<span><span class="va">simple_model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html" class="external-link">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">articulation_rate</span> <span class="op">~</span> </span>
<span>    <span class="va">attitude</span>,  </span>
<span>    data <span class="op">=</span> <span class="va">polite</span>,</span>
<span>    prior <span class="op">=</span> <span class="va">priors_simple_log</span>,</span>
<span>    family <span class="op">=</span> <span class="va">lognormal</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>And check the model fit again:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># posterior predictive check</span></span>
<span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html" class="external-link">pp_check</a></span><span class="op">(</span><span class="va">simple_model2</span>, nsamples <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<p>Much better, right? So by critically evaluating our model assumptions
and the actual data we discovered that a <code>lognormal</code>
distribution is a much better assumption about the underlying generative
model (i.e. how the data came to be).</p>
<p>Fantastic! Let’s have a look at the results (remember that the
results are now log transformed)</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract posterior coefficient and plot</span></span>
<span><span class="va">simple_model2</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span> <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/spread_draws.html" class="external-link">spread_draws</a></span><span class="op">(</span><span class="va">b_attitudepol</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>  <span class="co"># plot</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_attitudepol</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_halfeye.html" class="external-link">stat_halfeye</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"log(articulation rate)"</span><span class="op">)</span></span></code></pre></div>
<p>If you want to plot something more traditional, i.e. the posterior
values for polite and informal speech productions, we can use some neat
functions from other packages. This way we can plot the data in log
space and compare the two conditions immediately.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract posterior and plot predicted values for both levels</span></span>
<span><span class="va">polite</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://modelr.tidyverse.org/reference/data_grid.html" class="external-link">data_grid</a></span><span class="op">(</span><span class="va">attitude</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/add_predicted_draws.html" class="external-link">add_predicted_draws</a></span><span class="op">(</span><span class="va">simple_model2</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="co"># plot</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">.prediction</span>, y <span class="op">=</span> <span class="va">attitude</span>, fill <span class="op">=</span> <span class="va">attitude</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_halfeye.html" class="external-link">stat_halfeye</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html" class="external-link">scale_fill_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"#8970FF"</span>, <span class="st">"#FFA70B"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"articulation rate"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="adding-predictors">Adding predictors<a class="anchor" aria-label="anchor" href="#adding-predictors"></a>
</h3>
<p>This model estimates the effect of <code>attitude</code> on
articulation rate (<code>articulation_rate</code>). That.is.it. But what
if we also want to estimate the differences between attitude across
different experimental tasks? Let’s add <code>task</code> as a predictor
and add a prior for it as well. Let’s stick to weakly informative priors
again, centered on zero (we expect no difference of articulation rate
between different tasks and acknowledge the possibility of some variance
around that value).</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get prior</span></span>
<span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/get_prior.html" class="external-link">get_prior</a></span><span class="op">(</span></span>
<span> formula <span class="op">=</span> <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span>,</span>
<span>  data <span class="op">=</span> <span class="va">polite</span>, family <span class="op">=</span> <span class="va">lognormal</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># specify priors</span></span>
<span><span class="va">priors_multiple</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">attitudepol</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">tasknot</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># tun model</span></span>
<span><span class="va">multiple_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html" class="external-link">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span>,</span>
<span>  data <span class="op">=</span> <span class="va">polite</span>,</span>
<span>  prior <span class="op">=</span> <span class="va">priors_multiple</span>,</span>
<span>  family <span class="op">=</span> <span class="va">lognormal</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">multiple_model</span><span class="op">)</span></span></code></pre></div>
<p>Looking at the summary of the model, we get a table with two
coefficients for the population parameters <code>attitudepol</code> and
<code>tasknot</code>. Let’s remind ourselves that these reflect the
change in articulation rate from the reference level (attitude =
informal (<code>inf</code>), task = dialog completion task
(<code>dct</code>)) to attitude = polite (<code>attitudepol</code>) and
to task = note (<code>tasknot</code>), respectively.</p>
<p>We can inspect posteriors for both predictors just like we did
before:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract posterior coefficient attitudepol</span></span>
<span><span class="va">post_multiple_attitude</span> <span class="op">&lt;-</span> <span class="va">multiple_model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/spread_draws.html" class="external-link">spread_draws</a></span><span class="op">(</span><span class="va">b_attitudepol</span>, <span class="va">b_tasknot</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">post_multiple_attitude</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_halfeye.html" class="external-link">stat_halfeye</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_attitudepol</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"posterior for effect of attitude"</span>,</span>
<span>         x <span class="op">=</span> <span class="st">"log(articulation rate)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span></span>
<span> </span>
<span><span class="co"># Extract posterior coefficient tasknot </span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">post_multiple_attitude</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_halfeye.html" class="external-link">stat_halfeye</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_tasknot</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"posterior for effect of task"</span>,</span>
<span>         x <span class="op">=</span> <span class="st">"log(articulation rate)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span></span></code></pre></div>
<p>Both posterior distributions are very clearly located to the left of
zero, suggesting that there is both attitude and task affect
articulation-rate to some extend (given the model, the data, and the
prior assumptions)</p>
</div>
<div class="section level3">
<h3 id="adding-random-effects">Adding random effects<a class="anchor" aria-label="anchor" href="#adding-random-effects"></a>
</h3>
<p>So running Bayesian regression models is really not much different
from running frequentist regression models. Practically, the only
difference so far is that we specify prior knowledge. Conceptually, we
obviously interpret the output differently in terms of the inference we
draw, but this should be business as usual for you.</p>
<p>Now, we probably all suspect that this model is not quite appropriate
for the data, right? It does not take into account the fact that data
points are not independent from each other. There were multiple speakers
that produced multiple data points, so observations from these speakers
are not independent and we need to take that into account for robust
inference. So let’s also add an appropriate random effect structure,
including a by-subject random intercept as well as a by-subject random
slope for attitude.</p>
<p>We can write down the code to run this model easily, because we
should be familiar with the <code>lme4</code> syntax. <code>brms</code>
syntax handles random effect structure exactly like <code>lme4</code>
like so:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># model specification</span></span>
<span><span class="va">complex_model_formula</span> <span class="op">=</span> </span>
<span>  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span> <span class="op">+</span></span>
<span>    <span class="co"># add random intercept</span></span>
<span>    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="co"># add random slope</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">attitude</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span></span></code></pre></div>
<p>Looks familiar?</p>
<p>But what about priors? Do we need to specify priors for these new
elements as well? And if so how?</p>
<p>Generally, we encourage you to specify priors for all elements of
your model, so let us try this as well.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get prior</span></span>
<span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/get_prior.html" class="external-link">get_prior</a></span><span class="op">(</span></span>
<span>  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">attitude</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span>,  </span>
<span>   data <span class="op">=</span> <span class="va">polite</span>,</span>
<span>   family <span class="op">=</span> <span class="va">lognormal</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We need to specify four parameters for the Group-Level Effects. Three
of them are variance components that we will specify with half-cauchy
distributions, just like we did for the residual variance. The final
parameter is a correlation coefficient of the group level effects and
will be specified using the Lewandowski-Kurowicka-Joe prior (LKJ).</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># specify priors</span></span>
<span><span class="va">priors_complex</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">attitudepol</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">tasknot</span><span class="op">)</span>,</span>
<span>  <span class="co"># specify weakly informative prior for the random effects (slopes)</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span>, coef <span class="op">=</span> <span class="va">Intercept</span>, group <span class="op">=</span> <span class="va">subject</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span>, coef <span class="op">=</span> <span class="va">attitudeinf</span>, group <span class="op">=</span> <span class="va">subject</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span>, coef <span class="op">=</span> <span class="va">attitudepol</span>, group <span class="op">=</span> <span class="va">subject</span><span class="op">)</span>,</span>
<span>  <span class="co"># specify weakly informative prior for the correlation between random intercept and slope</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">lkj</span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">cor</span>, group <span class="op">=</span> <span class="va">subject</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>That is it. Now we can run the model. And we will add one new
argument to the <code><a href="https://paul-buerkner.github.io/brms/reference/brm.html" class="external-link">brm()</a></code> function: The <code>seed</code>
argument allows us to set a random seed. The sampling procedure has a
random initial state, so if you run this model on your machine, you will
get slightly different results from someone else. With <code>seed</code>
we can fix this initial state and obtain the exact same results. This is
great, because we can make our results fully reproducible that way.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Run model</span></span>
<span><span class="va">complex_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html" class="external-link">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span> <span class="op">+</span></span>
<span>    <span class="co"># add random intercept</span></span>
<span>    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="co"># add random slope</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">attitude</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span>,  </span>
<span>   data <span class="op">=</span> <span class="va">polite</span>,</span>
<span>   prior <span class="op">=</span> <span class="va">priors_complex</span>,</span>
<span>   family <span class="op">=</span> <span class="va">lognormal</span>,</span>
<span>  <span class="co"># set seed</span></span>
<span>   seed <span class="op">=</span> <span class="fl">999</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">complex_model</span><span class="op">)</span></span></code></pre></div>
<p>Let us walk through the summary here. We now have one part of the
table called “Group-Level Effects”. This part of the table gives us the
models estimates for four parameters: How much subjects’ baseline varies
(<code>sd(Intercept)</code>), how much they vary in the informal
condition (<code>sd(attitudeinf)</code>), how much subjects vary in the
polite condition (<code>sd(attitudepol)</code>), and what the
correlation between <code>sd(attitudeinf)</code> and
<code>sd(attitudepol)</code> is. As before, for all of these parameters,
we receive an <code>Estimate</code> which is the mean of the posterior
distribution and a range of plausible values within the 95% Credible
Interval (<code>l-95% CI</code> - <code>u-95% CI</code>). Except for the
correlation, the estimates are bound by 0, i.e. the variance can only be
positive. The correlation coefficient can vary between -1 and 1.</p>
<p>The second part of the summary table, i.e. the Population-Level
Effects, did not change and summarizes our regression coefficients for
the fixed effects. Just like before.</p>
<p>There we go. We have run a linear mixed effects model within the
Bayesian framework. We specified priors for both random and fixed
effects. What is left is interpreting the output.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract posterior coefficient politeness</span></span>
<span><span class="va">post_complex</span> <span class="op">&lt;-</span> <span class="va">complex_model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/spread_draws.html" class="external-link">spread_draws</a></span><span class="op">(</span><span class="va">b_attitudepol</span>, <span class="va">b_tasknot</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># plot</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">post_complex</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_halfeye.html" class="external-link">stat_halfeye</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_attitudepol</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"log(articulation rate)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="making-inference">Making inference<a class="anchor" aria-label="anchor" href="#making-inference"></a>
</h3>
<p>Now let’s use these posteriors to draw probability inferences. What
is the 95% credible interval for the <code>attitudepol</code>
coefficient and what is its probability of direction?</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># extract 95% HDI</span></span>
<span><span class="fu"><a href="http://mjskay.github.io/ggdist/reference/point_interval.html" class="external-link">hdi</a></span><span class="op">(</span><span class="va">post_complex</span><span class="op">$</span><span class="va">b_attitudepol</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co"># extract probability of direction</span></span>
<span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/p_direction.html" class="external-link">p_direction</a></span><span class="op">(</span><span class="va">post_complex</span><span class="op">$</span><span class="va">b_attitudepol</span><span class="op">)</span></span></code></pre></div>
<p>Fantastic! So our best estimate of the effect of attitude has a 95%
CrI between [-0.12, -0.01] and a 0.98 probability of being negative.
Although the majority of plausible values are negative, positive values
are still plausible (given the data, the model, and the priors).</p>
</div>
</div>
<div class="section level2">
<h2 id="exercise">Exercise<a class="anchor" aria-label="anchor" href="#exercise"></a>
</h2>
<p>Now it’s your turn: Our goal is it to run the following model:
<code>f0mn ~ attitude + (1 | subject) + (0 + attitude | subject)</code></p>
<ol style="list-style-type: lower-alpha">
<li>First, see which priors we need to specify using the
<code><a href="https://paul-buerkner.github.io/brms/reference/get_prior.html" class="external-link">get_prior()</a></code> function. (If you are unsure, see our code
examples above)</li>
</ol>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get prior</span></span>
<span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/get_prior.html" class="external-link">get_prior</a></span><span class="op">(</span></span>
<span> formula <span class="op">=</span> <span class="va">...</span>,</span>
<span> data <span class="op">=</span> <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Now specify weakly informative priors for all parameters. For the
intercept, chose a normal prior with mean = 0 and sd = 500. For
simplicity sake, let us just go for normally distributed priors for all
other parameters (mean = 0, sd = 100)</li>
</ol>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># specify priors</span></span>
<span><span class="va">priors_ex</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Now run the model with your specified priors. Use
<code>seed = 1111</code> in order for all of you to get the same
results.</li>
</ol>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Run model</span></span>
<span><span class="va">ex_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html" class="external-link">brm</a></span><span class="op">(</span></span>
<span>  formular <span class="op">=</span> <span class="va">...</span>,</span>
<span>  data <span class="op">=</span> <span class="va">...</span>,</span>
<span>  prior <span class="op">=</span> <span class="va">...</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">1111</span></span>
<span><span class="op">)</span></span></code></pre></div>
<ol start="4" style="list-style-type: lower-alpha">
<li>Extract the posteriors for the coefficient attitudepol and plot
it.</li>
</ol>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract posterior coefficient politeness</span></span>
<span><span class="va">ex_post</span> <span class="op">&lt;-</span> <span class="va">ex_model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/spread_draws.html" class="external-link">spread_draws</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="va">...</span></span></code></pre></div>
<ol start="5" style="list-style-type: lower-alpha">
<li>Now let’s use the posteriors to draw probability inferences. What is
the 95% credible interval for the <code>attitudepol</code> coefficient
and what is its probability of direction?</li>
</ol>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># extract 95% HDI</span></span>
<span><span class="fu"><a href="http://mjskay.github.io/ggdist/reference/point_interval.html" class="external-link">hdi</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># extract probability of direction</span></span>
<span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/p_direction.html" class="external-link">p_direction</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre></div>
<ol start="6" style="list-style-type: lower-alpha">
<li>But hold on. Is the model fit okay? Critically check the model fit
with <code><a href="https://mc-stan.org/bayesplot/reference/pp_check.html" class="external-link">pp_check()</a></code>. Do you think the model and the priors
capture the generative process appropriately? What might be the issue?
Can you fix it?</li>
</ol>
<p><br></p>
<!-- Solutions -->
<!-- (a) 
get_prior(
 formula = 
   f0mn ~ 
   attitude +
   (1 | subject) + 
   (0 + attitude | subject),
  data = polite
)
-->
<!-- (b) 
priors_ex <- c(
  prior(normal(0, 500), class = Intercept),
  prior(normal(0, 100), class = b, coef = attitudepol),
  # specify weakly informative prior for the random effects (slopes)
  prior(normal(0, 100), class = sd, coef = Intercept, group = subject),
  prior(normal(0, 100), class = sd, coef = attitudeinf, group = subject),
  prior(normal(0, 100), class = sd, coef = attitudepol, group = subject),
  # specify weakly informative prior for the correlation between random intercept and slope
  prior(lkj(2), class = cor, group = subject),
  prior(normal(0, 100), class = sigma)
)
-->
<!-- (c)
ex_model <- brm(
  f0mn ~ 
    attitude +
    (1 | subject) +
    (0 + attitude | subject),  
   data = polite,
   prior = priors_ex,
   seed = 1111,
)
-->
<!-- (d)
ex_post <- ex_model %>%
  spread_draws(b_attitudepol)

ggplot(ex_post) + 
  stat_halfeye(aes(x = b_attitudepol)) +
  labs(x = "fundamental frequency in Hz")
-->
<!-- (e)
hdi(ex_post$b_attitudepol)
p_direction(ex_post$b_attitudepol)
-->
<!-- (f)
pp_check(ex_model, nsamples = 100)

Doesn't capture bimodality well and over estimates the probability of value between 0 and 50.
One reason for this is that f0 is also bound to zero and very low values are virtually impossible.
Again, a lognormal link function is probably more appropriate.

priors_ex_log <- c(
  prior(normal(0, 6), class = Intercept),
  prior(normal(0, 3), class = b, coef = attitudepol),
  # specify weakly informative prior for the random effects (slopes)
  prior(cauchy(0, .1), class = sd, coef = Intercept, group = subject),
  prior(cauchy(0, .1), class = sd, coef = attitudeinf, group = subject),
  prior(cauchy(0, .1), class = sd, coef = attitudepol, group = subject),
  # specify weakly informative prior for the correlation between random intercept and slope
  prior(lkj(2), class = cor, group = subject),
  prior(cauchy(0, .1), class = sigma)
)

Run model for priors only

ex_model_log_priors <- brm(
  f0mn ~ 
    attitude +
    (1 | subject) +
    (0 + attitude | subject),  
   data = polite,
   sample_prior = "only",
   family = lognormal,
   prior = priors_ex_log,
   seed = 1111
)

conditional_effects(ex_model_log_priors)

Run model

ex_model_log <- brm(
  f0mn ~ 
    attitude +
    (1 | subject) +
    (0 + attitude | subject),  
   data = polite,
   family = lognormal,
   prior = priors_ex_log,
   seed = 1111
)

pp_check(ex_model_log, nsamples = 100)

Much better!

-->
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Stefano Coretta, Joseph V. Casillas, Timo Roettger.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
