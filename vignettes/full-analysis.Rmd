---
title: "Fully worked-out analysis using a Bayesian regression with brms"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Fully worked-out analysis using a Bayesian regression with brms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(learnB4SS)
library(tidyverse)
theme_set(theme_minimal())
library(extraDistr)
library(HDInterval)
library(brms)


data("incomplete")

b4ss_colors <- c(purple = "#8970FF", orange = "#FFA70B")

scale_fill_b4ss <- function(...) {
  scale_fill_manual(..., values = c(b4ss_colors[[1]], b4ss_colors[[2]]))
}

scale_color_b4ss <- function(...) {
  scale_color_manual(..., values = c(b4ss_colors[[1]], b4ss_colors[[2]]))
}
```

# Study overview and data

```{r incomplete}
glimpse(incomplete)
```

# Model formula

```{r m1-bf}
m1_bf <- brmsformula(
  correct ~
    correct_voicing *
    repetitiontype +
    # random slopes for interaction across listeners
    (correct_voicing * repetitiontype | listener) +
    # random slopes for interaction across speaker voices
    (correct_voicing * repetitiontype | speaker_voice) +
    # random slopes for interaction across minimal pairs
    (correct_voicing * repetitiontype | item_pair),
  family = bernoulli()
)
```


# Priors and prior predictive checks

## Prior distribution of the outcome variable (likelihood, family)

$$correct_i \sim Bernoulli(p)$$

```{r bernoulli}
y <- dbern(c(0, 1), p = 0.75)

ggplot() +
  aes(c("0", "1"), y) +
  geom_linerange(aes(ymin = 0, ymax = y), size = 2, colour = b4ss_colors) +
  geom_point(size = 5, colour = b4ss_colors) +
  ylim(0, 1) +
  labs(x = "outcome", y = "p")
```

## Get priors

```{r m1-prior-default}
# get_prior(m1_bf, data = incomplete)
get_prior(m1_bf, data = incomplete) %>%
  as_tibble() %>%
  select(prior:group)
```

## Log-odds space

```{r p-log-odds}
dots <- tibble(
  p = seq(0.1, 0.9, by = 0.1),
  log_odds = qlogis(p)
)

tibble(
  p = seq(0, 1, by = 0.001),
  log_odds = qlogis(p)
) %>%
  ggplot(aes(p, log_odds)) +
  geom_hline(yintercept = 0, alpha = 0.5) +
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  geom_line(size = 2, colour = b4ss_colors[2]) +
  geom_point(data = dots, size = 4, colour = b4ss_colors[1]) +
  scale_x_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(-6, 6, by = 2), minor_breaks = NULL) +
  labs(
    title = "Correspondence between probabilities and log-odds",
    x = "probability",
    y = "log-odds"
  )
```

```{r logis}
# log-odds = 0; get probability
glue::glue("Log-odds 0 = p(", plogis(0), ")")
# p = 0.5; get log-odds
glue::glue("p(0.5) = log-odds ", qlogis(0.5))

cat("\n\n")

# log-odds = 1.5; get probability
glue::glue("Log-odds 1.5 = p(", round(plogis(1.5), 4), ")")
# p = 0.5; get log-odds
glue::glue("p(0.8176) = log-odds ", round(qlogis(0.8175745), 4))
```

## Prior for the intercept

```{r prior-intercept}
# Log-odds to p
plogis(-6) # ~= 0 
plogis(6) # ~= 1
```



```{r prior-intercept-plot}
x <- seq(-15, 15, by = 0.1)
# 95% Cri [-6, +6] => SD = 6/2 = 3
y <- dnorm(x, mean = 0, sd = 3)

ggplot() +
  aes(x, y) +
  geom_line(size = 1.5, colour = b4ss_colors[1]) +
  labs(x = "log-odds")
```

## Prior for b

```{r prior-b}
# Log-odds to odds
exp(-2) # ~= 0
exp(2) # ~= 7
```

```{r prior-b-plot}
x <- seq(-4, 4, by = 0.1)
# 95% Cri [-2, +2] => SD = 2/2 = 1
y <- dnorm(x, mean = 0, sd = 1)

ggplot() +
  aes(x, y) +
  geom_line(size = 1.5, colour = b4ss_colors[1]) +
  labs(x = "log-odds")
```

## Prior for sd

```{r prior-sd}
inverseCDF(c(0.025, 0.975), phcauchy, sigma = 0.1)
```

```{r prior-sd-plot}
x <- seq(0, 3, by = 0.01)
y <- dhcauchy(x, sigma = 0.1)

ggplot() +
  aes(x, y) +
  geom_line(size = 1, colour = b4ss_colors[2]) +
  labs(x = "log-odds")
```

## Set priors

```{r priors}
priors <- c(
  prior(normal(0, 3), class = Intercept),
  prior(normal(0, 1), class = b),
  prior(cauchy(0, 0.1), class = sd),
  prior(lkj(2), class = cor)
)
```

## Prior predictive checks

```{r prior-pc}
m1_priorpc <- brm(
  m1_bf,
  data = incomplete,
  prior = priors,
  sample_prior = "only",
  cores = 4
)
```

```{r prior-pc-plot}
conditional_effects(m1_priorpc, effects = "correct_voicing:repetitiontype")
```

## Let's try VERY strong priors for comparison

```{r priors-strong}
priors_strong <- c(
  prior(normal(2, 0.1), class = Intercept),
  prior(normal(1, 0.1), class = b),
  prior(cauchy(0, 0.1), class = sd),
  prior(lkj(2), class = cor)
)
```

```{r priors-strong-pc}
m1_priorpc_strong <- brm(
  m1_bf,
  data = incomplete,
  prior = priors_strong,
  sample_prior = "only",
  cores = 4
)
```

```{r priors-strong-pc-plot}
conditional_effects(m1_priorpc_strong, effects = "correct_voicing:repetitiontype")
```

# Model output and interpretation

# Visual effects

A quick and dirty way to assess the posterior predictions is using the `conditional_effects()` function. It is also useful because it plots the data into the original scale.

```{r conditional_effects}

# quick and dirty plot on the original scale
conditional_effects(m1_bf)

```
We can also plot the posterior distributions of our population-level coefficients. This can be conveniently done with the `bayesplot` package. 

```{r forest_plot}

posterior <- as.matrix(m1_bf)

mcmc_areas(posterior,
           pars = c("b_Intercept", 
                    "b_correct_voicingvoiceless", 
                    "b_repetitiontyperepeated", 
                    "b_correct_voicingvoiceless:repetitiontyperepeated"),
           # arbitrary threshold for shading probability mass
           prob = 0.83) 

```

For more traditional plotting of the actual levels of the predictors, we can use the `data_grid()` and `add_fitted_draws()` functions. Here is an example.

```{r levels_plot}

post_plot <- 
  incomplete %>% 
  data_grid(correct_voicing, repetitiontype) %>%
  add_fitted_draws(m1_bf, n = 4000) %>%
  # plot
  ggplot(aes(y = .value, x = correct_voicing, 
             fill = correct_voicing)) +
  # density plus CrIs
  stat_halfeye() +
  # reference line at chance level = 0.5
  geom_hline(yintercept = 0.5, lty = "dashed") +
  # split by repetition type
  facet_grid(~repetitiontype) +
  # color code
  scale_fill_manual(values = c("#8970FF", "#FFA70B")) + 
  #scale_color_manual(values = c("#8970FF", "#FFA70B")) +
  # rename y axis
  labs(y = "probability of correct",
       x = "underlying voicing")

post_plot
```

If you want to add the actual aggregated accuracy for each listener to the plot (for example), you can add that information on top. Makes for a very informative plot.

```{r levels_plot-2, message = FALSE}

#aggregate
incomplete_agg <- incomplete %>% 
  group_by(listener, correct_voicing, repetitiontype) %>% 
  summarise(.value = mean(as.numeric(correct)))

post_plot +
  geom_point(data = incomplete_agg,
             aes(y = .value, 
                 x = correct_voicing, 
                 fill = correct_voicing),
             pch = 21, alpha = 0.5,
             position = position_nudge(x = -0.1))
```
