---
title: "Application to regression III - Bayesian inference"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Application to regression III - Bayesian inference}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  message = F, 
  warning = F, 
  fig.retina = 2
)
```

## Get set up

First, let's load the packages and data we will be using. 

```{r setup}
# Packages
library("learnB4SS")
library("dplyr")
library("ggplot2")
library("brms")
library("bayestestR")

# Data
data(polite)
```


## Credible intervals

The first tool we will consider for making statistical inferences in a Bayesian framework is the credible interval. 
If you have heard of Bayesian inference before, there is a good chance you have also heard of credible intervals. 
We could describe them as the Bayesian counterpart to confidence intervals under a frequentist framework. 

All we need to calculate a credible interval is a probability distribution. 
In R, this can be as simple as a vector of values. 
We'll illustrate by sampling fake data and calculating a CI using base R.

```{r, credible-intervals1}
# Generate 'fake' posterior by sampling values from a normal distribution with 
# mean of 5 and SD of 3
posterior <- rnorm(n = 1000, mean = 5, sd = 3)

# Use quantile function on posterior
quantile(posterior, c(0.025, 0.975))
```

We can see that the 95% CI for our posterior is `r quantile(posterior, c(0.025, 0.975))`. 

We can simplify the process even more using the `hdi` function from the `bayestestR` package. 
This has some other benefits that we will see in a bit.

```{r, credible-intervals2}
# bayesTestR::hdi
hdi_ex1 <- hdi(posterior)
hdi_ex1
```

Notice that the ranges are slightly different. 
This is because the HDI, highest density interval, is a special type of credible interval. 
There are several methods for calculating a CI, but we won't go into that now. 
For our purposes we will stick with the HDI. 


One advantage to using the `hdi` function from the `bayestestR` package is that it also has print methods. 
This means we can wrap the `plot()` function around our `hdi` object, like this: 

```{r, credible-intervals3, out.width="100%"}
# Generate a plot from the hdi object
plot(hdi_ex1)
```

Beautiful!  

Now let's repeat this using a real posterior from a model object. 

Recall that we fit this intercept-only model previously: 

```{r, credible-intervals-hide1, include=F}
# Intercept-only model
b_mod_00 <- brm(articulation_rate ~ 1, data = polite, 
  file = here::here("./vignettes/b_mod_00"))
```

```{r, credible-intervals-mod00, eval=F}
# Intercept-only model
b_mod_00 <- brm(articulation_rate ~ 1, data = polite)
```

Let's get the posterior distribution and calculate the HDI of the intercept. 

```{r, credible-intervals-mod00-1}
# Get posterior samples
post_00 <- posterior_samples(b_mod_00)

# Calculate HDI
hdi_ex2 <- hdi(post_00$b_Intercept)
hdi_ex2
```

So we are 95% certain that the value of the intercept falls between about 6.5 and 6.8. 
Cool. 
Let's plot this as well.

```{r, credible-intervals-mod00-2, out.width="100%"}
# Plot it
plot(hdi_ex2)
```


Now we repeat this process with yesterdays model that included the predictor `attitude`. 

Here is the model again, just in case: 

```
MODEL here
```


```
b_mod_01 <- readRDS(here::here("./vignettes/b_mod_01.rds"))
post_01 <- posterior_samples(b_mod_01)

quantile(post_01$b_attitudepol, c(0.025, 0.975))
hdi_ex3 <- hdi(post_01$b_attitudepol)
hdi_ex3
plot(hdi_ex3)


# We can also use the function directly on the model object
hdi(b_mod_01)
hdi_on_mod <- hdi(b_mod_01)
plot(hdi_on_mod, show_intercept = T)

```













```{r, p-direction, include=F, eval=F}
# We can use the p_direction function to calculate the PD (PME) on a vector
p_direction(posterior)

# On a single column (parameter) from the posterior
p_direction(post_00$b_Intercept)
p_direction(post_01$b_attitudepol)

# And also on the model object itself
p_direction(b_mod_01)

# There are also print methods
pd_on_mod <- p_direction(b_mod_01)
plot(pd_on_mod, show_intercept = T)


# To build intuition about how the PD corresponds with a frequentist p-value
# we can use pd_to_p and p_to_pd to convert between the two (not recommended)
pd_to_p(0.987)
p_to_pd(0.01)

```



```{r, pd-p-comparison, fig.width=14, fig.height=8, echo=F, include=F, eval=F}
tibble(`Prob. of direction` = seq(0.95, 1.0, 0.0025)) %>%
  mutate(., `p-value` = pd_to_p(`Prob. of direction`)) %>% 
  ggplot(., aes(x = `p-value`, y = `Prob. of direction`)) + 
    geom_rect(aes(xmin = 0, xmax = 0.05, ymin = -Inf, ymax = Inf), 
      fill = "lightblue", alpha = 0.01) + 
    geom_line() + 
    geom_point(aes(fill = `p-value` < 0.05), 
      size = 5, pch = 21, color = "white", stroke = 2) + 
    scale_fill_manual(name = "p-value < 0.05", 
      values = c("#8970FF", "#FFA70B")) + 
    scale_x_continuous(breaks = seq(0.0, 0.1, 0.01))
```





















```{r, rope-ex, include=F, eval=F}
# Like before, we can operate on a single distribution stored in a vector
# The `rope` function will calculate the proportion of the posterior that falls 
# within our rope range. 
rope(posterior)

# We can set the rope_range and the size of the CI
rope(posterior, rope_range = c(-0.1, 0.1), ci = 0.95)

# The default is set to 95% and +/-0.1, unless the input is a Bayesian model
# In that case, the function `rope_range` is used to calculate a ROPE 
# (following Kruschke 2018, see ?rope_range). 
rope_range(b_mod_01)

# Let's run it on our model
rope_on_mod01 <- rope(b_mod_01, ci = 0.95)
rope_on_mod01

# There are printing methods for rope objects
plot(rope_on_mod01, show_intercept = T)

# We can also set multiple ROPEs
rope_on_mod02 <- rope(b_mod_01, ci = c(0.8, 0.85, 0.9, 0.95))
rope_on_mod02
plot(rope_on_mod02)
```















<!--
PRACTICAL (longer): Run model on Bodoâ€™s data with prepared RMarkdown

think of new hypotheses to test, use your favorite method (or all of them)

Here are a few examples: 
--> 

