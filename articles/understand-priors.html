<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Understand and explore priors • learnB4SS</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Understand and explore priors">
<meta property="og:description" content="learnB4SS">
<meta property="og:image" content="https://learnb4ss.github.io/learnB4SS/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">learnB4SS</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.0.7.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Get started
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/install-brms.html">Install brms and dependencies</a>
    </li>
    <li>
      <a href="../articles/install-learnb4ss.html">Install the learnB4SS package</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Slides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Day 1</li>
    <li>
      <a href="https://learnb4ss.github.io/slides/00_intro/index.pdf">0. Introduction</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/01_a2r_initial_demo/index.html">1. Application to regression I — Demo</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/02_bayes_theorem/index.pdf">2. Bayes theorem — How does it work?</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/03_a2r_priors_and_bayesian_updating/index.html">3. Application to regression II — Priors and Bayesian updating</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/04_nhst_vs_bayesian_inference/index.pdf">4. NHST vs. Bayesian inference</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Day 2</li>
    <li>
      <a href="https://learnb4ss.github.io/slides/05_review/index.html">5. Interim review</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/06_a2r_inference_over_posterior/index.html">6. Application to regression III — More Bayesian inference</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/07_more_priors/index.html">7. More on priors</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/08_a2r_leveling_up/index.pdf">8. Application to regression IV — Leveling up</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/09_sample_the_posterior/index.html">9. Sampling from the posterior</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/10_wrap_up/index.pdf">10. Wrap up</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Day 1</li>
    <li>
      <a href="../articles/ex_03.html">3. Application to regression II — Priors and Bayesian updating</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Day 2</li>
    <li>
      <a href="../articles/ex_06.html">6. Application to regression III - More Bayesian inference</a>
    </li>
    <li>
      <a href="../articles/ex_08.html">8. Application to regression IV - Leveling up to hierarchical models</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Day 3</li>
    <li>
      <a href="../articles/full-analysis.html">Fully worked-out analysis</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Documentation</a>
</li>
<li>
  <a href="../articles/faqs.html">FAQs</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extras
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/why-bayes.html">Why Bayesian?</a>
    </li>
    <li>
      <a href="../articles/glossary.html">Glossary</a>
    </li>
    <li>
      <a href="../articles/understand-priors.html">Understand priors</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/learnB4SS/learnB4SS/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="understand-priors_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Understand and explore priors</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/learnB4SS/learnB4SS/blob/master/vignettes/understand-priors.Rmd"><code>vignettes/understand-priors.Rmd</code></a></small>
      <div class="hidden name"><code>understand-priors.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme_get.html">theme_set</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/learnB4SS/learnB4SS">learnB4SS</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">HDInterval</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/twolodzko/extraDistr">extraDistr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/paul-buerkner/brms">brms</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">emotion</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">vowels</span><span class="op">)</span></code></pre></div>
<div id="overview" class="section level1">
<h1 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h1>
<p>This vignette digs a bit deeper into priors for different types of outcome/response variables. We will cover outcome variables that follow these distributions: normal/Gaussian, log-normal, binomial/Bernoulli, poisson, and beta.</p>
</div>
<div id="normalgaussian" class="section level1">
<h1 class="hasAnchor">
<a href="#normalgaussian" class="anchor"></a>Normal/Gaussian</h1>
<p>Let’s start off with an outcome variable distributed according to a normal/Gaussian distribution.</p>
<p>In fact, we hardly ever work with truly normally distributed variables. So for this example we will look at a data set of lexical emotional valence.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">emotion</span>
<span class="co">#&gt; # A tibble: 1,000 x 2</span>
<span class="co">#&gt;    word         valence</span>
<span class="co">#&gt;    &lt;chr&gt;          &lt;dbl&gt;</span>
<span class="co">#&gt;  1 classroom      0.57 </span>
<span class="co">#&gt;  2 worker         0.95 </span>
<span class="co">#&gt;  3 climb          0.62 </span>
<span class="co">#&gt;  4 photographer   1.71 </span>
<span class="co">#&gt;  5 downward      -1    </span>
<span class="co">#&gt;  6 loose         -0.480</span>
<span class="co">#&gt;  7 scanner        0.57 </span>
<span class="co">#&gt;  8 kooky          1.42 </span>
<span class="co">#&gt;  9 credence       0.79 </span>
<span class="co">#&gt; 10 fog            0.770</span>
<span class="co">#&gt; # … with 990 more rows</span></code></pre></div>
<p>The <code>emotion</code> tibble contains a list of 1000 English words (<code>word</code>) and their emotional valence (<code>valence</code>). Emotional valence is given as a number between <code>-4</code> and <code>+4</code>, which correspond to “bad valence” and “good valence” respectively.</p>
<p>The variable <code>valence</code> is in principle distributed according to a normal/Gaussian distribution (simply “normal” from now on). NOTE that the probability distribution of the outcome variable (aka likelihood, family) should not be chosen based on visual inspection, but based on conceptual principles.</p>
<p>Another word of warning is that plotting continuous outcome variables with <code><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density()</a></code> does not allow us to assess which distribution the variable follows, because the data might have been generated by a mixture of distributions.</p>
<p>A quick plot of the outcome variable should just be used to ensure that the data is ok (i.e. doesn’t contain errors).</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">emotion</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">valence</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_rug.html">geom_rug</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></code></pre></div>
<p><img src="understand-priors_files/figure-html/valence-density-1.png" width="700"></p>
<p>All seems good.</p>
<p>Now, what we want to do is simply to model the distribution of <code>valence</code>.</p>
<p><code>valence</code> follows a normal distribution:</p>
<p><span class="math display">\[valence_i \sim Normal(\mu, \sigma)\]</span></p>
<p>So in fact we want to estimate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> from the data.</p>
<p>We need to set a prior probability distribution (or simply prior) for <span class="math inline">\(\mu\)</span> and one prior for <span class="math inline">\(\sigma\)</span>.</p>
<p>A go-to prior distribution for <span class="math inline">\(\mu\)</span> is yet another normal distribution, with its own <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\sigma_1\)</span>.</p>
<p><span class="math display">\[\mu \sim Normal(\mu_1, \sigma_1)\]</span></p>
<p>As a general rule, we recommend using so-called <strong>regularising priors</strong> by setting <span class="math inline">\(\mu_1\)</span> to <code>0</code>.</p>
<p><span class="math display">\[\mu \sim Normal(0, \sigma_1)\]</span></p>
<p>To decide what value to assign to <span class="math inline">\(\sigma_1\)</span>, we can use the <strong>empirical rule</strong>: the 95% CrI of a normal distribution is the interval contained within the range defined by <span class="math inline">\(\mu \pm 2\sigma\)</span>.</p>
<p>Since <code>valence</code> ranges between <code>-4</code> and <code>+4</code> by definition, a conservative approach for <span class="math inline">\(\mu\)</span> is to allow for values between <code>-8</code> and <code>+8</code>.</p>
<p>Since <span class="math inline">\(\mu_1 = 0\)</span>, then <span class="math inline">\(\sigma_1\)</span> is <span class="math inline">\(8/2 = 4\)</span>.</p>
<p><span class="math display">\[\mu \sim Normal(0, 4)\]</span></p>
<p>This is how <span class="math inline">\(Normal(0, 4)\)</span> looks like.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">15</span>, <span class="fl">15</span>, by <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">0</span>, <span class="fl">4</span><span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p><img src="understand-priors_files/figure-html/mu-prior-1.png" width="700"></p>
<p>So now we know which prior we will set for <span class="math inline">\(\mu\)</span>.</p>
<p>For <span class="math inline">\(\sigma\)</span>, one can choose from a normal distribution, a Student-t distribution, or a Half-Cauchy distribution.</p>
<p>We will go with the latter.</p>
<p><span class="math display">\[\sigma \sim HalfCauchy(x, \gamma)\]</span></p>
<p>With Half-Cauchy distributions you can safely set <span class="math inline">\(x = 0\)</span>.</p>
<p><span class="math display">\[\sigma \sim HalfCauchy(0, \gamma)\]</span></p>
<p>We cannot use the empirical rule to decide what value <span class="math inline">\(\gamma\)</span> should have, because the rule works only with normal distributions.</p>
<p>Instead, we can use the <code><a href="https://rdrr.io/pkg/HDInterval/man/inverseCDF.html">inverseCDF()</a></code> function from the HDInterval package (see the function documentation for a full explanation).</p>
<p>We don’t really have an idea of what the standard deviation for the <code>valence</code> scores might be, and we cannot calculate the standard deviation from the data (that would be cheating!).</p>
<p>So we just go with a quite weakly informative prior.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># phcauchy is from the extraDistr package</span>
<span class="co"># If you are wondering why 0.025 and 0.975, that is the range that gives you</span>
<span class="co"># a 95% CrI/HDI.</span>
<span class="co"># Note that the phcauchy function calls gamma "sigma" but it means the same here.</span>
<span class="fu"><a href="https://rdrr.io/pkg/HDInterval/man/inverseCDF.html">inverseCDF</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span>, <span class="va">phcauchy</span>, sigma <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="co">#&gt; [1]  0.03929027 25.45168269</span></code></pre></div>
<p>The functions returns the lower and upper boundary of the 95% HDI (Highest Density Interval). The range <code>[0, 25]</code> for the standard deviation encompasses a very large range of values, given the range of <code>valence</code> (<code>[-4, +4]</code>), making the prior a weakly informative one.</p>
<p>The prior for <span class="math inline">\(\sigma\)</span> then is:</p>
<p><span class="math display">\[\sigma \sim HalfCauchy(0, 1)\]</span></p>
<p>To sum up:</p>
<p><span class="math display">\[
\begin{aligned}
valence_i &amp; \sim Normal(\mu, \sigma)\\
\mu &amp; \sim Normal(0, 4)\\
\sigma &amp; \sim HalfCauchy(0, 1)
\end{aligned}
\]</span></p>
<p>The corresponding code for <span class="math inline">\(valence_i \sim Normal(\mu, \sigma)\)</span> is:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>
  <span class="va">valence</span> <span class="op">~</span> <span class="fl">1</span>,
  data <span class="op">=</span> <span class="va">emotion</span>,
  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<p>We can check which priors we should specify:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/pkg/brms/man/get_prior.html">get_prior</a></span><span class="op">(</span>
  <span class="va">valence</span> <span class="op">~</span> <span class="fl">1</span>,
  data <span class="op">=</span> <span class="va">emotion</span>,
  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>
<span class="op">)</span>
<span class="co">#&gt;                   prior     class coef group resp dpar nlpar bound  source</span>
<span class="co">#&gt;  student_t(3, 0.7, 2.5) Intercept                                  default</span>
<span class="co">#&gt;    student_t(3, 0, 2.5)     sigma                                  default</span></code></pre></div>
<p>The brms code for setting the priors is:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">priors_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="co"># class Intercept = mu</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">norma</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">4</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,
  <span class="co"># no need to specify that cauchy should be half</span>
  <span class="co"># that is done automatically by brms</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<p>At this point you would normally do prior predictive checks. We will show you how in the next example.</p>
<p>After you made sure the prior predictive checks are fine, you would go on to run the model with your priors (not run here).</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>
  <span class="va">valence</span> <span class="op">~</span> <span class="fl">1</span>,
  data <span class="op">=</span> <span class="va">emotion</span>,
  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>,
  prior <span class="op">=</span> <span class="va">priors_1</span>
<span class="op">)</span></code></pre></div>
</div>
<div id="log-normal" class="section level1">
<h1 class="hasAnchor">
<a href="#log-normal" class="anchor"></a>Log-normal</h1>
<p>Several measures that can only take on positive values, like segment duration, tend to have a skewed probability distribution. One such type of distribution is the <strong>log-normal</strong> distribution.</p>
<p>To illustrate how to run a Bayesian regression model with log-normal data, we will use a data set of vowel duration. Segment durations are known to follow a log-normal distribution, since durations can only be positive. This characteristics produces the typical right skew of log-normal data.</p>
<p>Let’s have a look at the data.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html">glimpse</a></span><span class="op">(</span><span class="va">vowels</span><span class="op">)</span>
<span class="co">#&gt; Rows: 886</span>
<span class="co">#&gt; Columns: 9</span>
<span class="co">#&gt; $ item          &lt;dbl&gt; 20, 2, 11, 1, 15, 10, 13, 3, 14, 19, 4, 6, 16, 17, 5, 23…</span>
<span class="co">#&gt; $ speaker       &lt;chr&gt; "it01", "it01", "it01", "it01", "it01", "it01", "it01", …</span>
<span class="co">#&gt; $ word          &lt;chr&gt; "pugu", "pada", "poco", "pata", "boco", "podo", "boto", …</span>
<span class="co">#&gt; $ v1_duration   &lt;dbl&gt; 95.23720, 138.96844, 126.93226, 127.49888, 132.33310, 12…</span>
<span class="co">#&gt; $ c2_voicing    &lt;chr&gt; "voiced", "voiced", "voiceless", "voiceless", "voiceless…</span>
<span class="co">#&gt; $ vowel         &lt;chr&gt; "u", "a", "o", "a", "o", "o", "o", "a", "o", "u", "a", "…</span>
<span class="co">#&gt; $ c2_place      &lt;chr&gt; "velar", "coronal", "velar", "coronal", "velar", "corona…</span>
<span class="co">#&gt; $ speech_rate   &lt;dbl&gt; 4.893206, 5.015636, 4.819541, 5.031662, 5.063435, 5.0632…</span>
<span class="co">#&gt; $ speech_rate_c &lt;dbl&gt; -0.55937531, -0.43694485, -0.63303978, -0.42091937, -0.3…</span></code></pre></div>
<p>And let’s plot the raw vowel duration.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">vowels</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">v1_duration</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_rug.html">geom_rug</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p><img src="understand-priors_files/figure-html/vow-duration-1.png" width="700"></p>
<p>We can start off with this simple formula:</p>
<p><span class="math display">\[vow\_dur_i \sim Lognormal(\mu_i, \sigma)\]</span></p>
<p>Vowel duration is distributed according to a log-normal distribution, which has a mean <span class="math inline">\(\mu\)</span> and a standard deviation <span class="math inline">\(\sigma\)</span>. We want to estimate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> from the data.</p>
<p>This time though, we also have a few predictors we are interested in: C2 voicing (voiceless, voiced), C2 place of articulation (coronal, velar), vowel (/a/, /o/, /u/), and speech rate (syllables per second).</p>
<p>The predictors of a linear model are assumed to have an effect on <span class="math inline">\(\mu\)</span>. The following formula for <span class="math inline">\(\mu\)</span> from above should make this evident:</p>
<p><span class="math display">\[
\begin{aligned}
\mu_i &amp; = \alpha + \beta_1 \times c2voicing_i + \beta_2 \times c2poa_i \\
&amp; + \beta_3 \times vowelO_i + \beta_4 \times vowelU_i \\
&amp; + \beta_5 \times srate_i
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\alpha\)</span> is the parameter of the model intercept, while the <span class="math inline">\(\beta\)</span> parameters are the coefficients of the predictors.</p>
<p>For each of these parameters we need to set a prior.</p>
<p>To be continued…</p>
<p><br></p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Stefano Coretta, Joseph V. Casillas, Timo Roettger.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
