<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Application to regression IV - Leveling up to hierarchical models • learnB4SS</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Application to regression IV - Leveling up to hierarchical models">
<meta property="og:description" content="learnB4SS">
<meta property="og:image" content="https://learnb4ss.github.io/learnB4SS/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">learnB4SS</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Get started
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/install-brms.html">Install brms and dependencies</a>
    </li>
    <li>
      <a href="../articles/install-learnb4ss.html">Install the learnB4SS package</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Slides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Day 1</li>
    <li>
      <a href="https://learnb4ss.github.io/slides/00_intro/index.pdf">0. Introduction</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/01_a2r_initial_demo/index.html">1. Application to regression I — Demo</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/02_bayes_theorem/index.pdf">2. Bayes theorem — How does it work?</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/03_a2r_priors_and_bayesian_updating/index.html">3. Application to regression II — Priors and Bayesian updating</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/04_nhst_vs_bayesian_inference/index.pdf">4. NHST vs. Bayesian inference</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Day 2</li>
    <li>
      <a href="https://learnb4ss.github.io/slides/05_review/index.html">5. Interim review</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/06_a2r_inference_over_posterior/index.html">6. Application to regression III — More Bayesian inference</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/07_more_priors/index.html">7. More on priors</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/08_a2r_leveling_up/index.pdf">8. Application to regression IV — Leveling up</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/09_sample_the_posterior/index.html">9. Sampling from the posterior</a>
    </li>
    <li>
      <a href="https://learnb4ss.github.io/slides/10_wrap_up/index.html">10. Wrap up</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Day 1</li>
    <li>
      <a href="../articles/ex_03.html">3. Application to regression II — Priors and Bayesian updating</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Day 2</li>
    <li>
      <a href="../articles/ex_06.html">6. Application to regression III - More Bayesian inference</a>
    </li>
    <li>
      <a href="../articles/ex_08.html">8. Application to regression IV - Leveling up to hierarchical models</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Documentation</a>
</li>
<li>
  <a href="../articles/faqs.html">FAQs</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/learnB4SS/learnB4SS/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="ex_08_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Application to regression IV - Leveling up to hierarchical models</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/learnB4SS/learnB4SS/blob/master/vignettes/ex_08.Rmd"><code>vignettes/ex_08.Rmd</code></a></small>
      <div class="hidden name"><code>ex_08.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Packages</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/learnB4SS/learnB4SS">learnB4SS</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://modelr.tidyverse.org">modelr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/paul-buerkner/brms">brms</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mjskay.github.io/tidybayes/">tidybayes</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/bayestestR/">bayestestR</a></span><span class="op">)</span>

<span class="co"># Data</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">polite</span><span class="op">)</span></code></pre></div>
<div id="walkthrough" class="section level1">
<h1 class="hasAnchor">
<a href="#walkthrough" class="anchor"></a>Walkthrough</h1>
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>Until now, we have only dealt with very simple models, most of which are just not particularly relevant for what we actually do in our research, right? So in this section, we will level up. We will add additional parameters to our regression in the form of fixed effects and random effect. Sounds much more like the stuff you want to do, right? We are going to estimate these parameters and specify appropriate priors for them. After this session you will be much closer to being an operational Bayesian for your actual research.</p>
</div>
<div id="a-simple-model" class="section level2">
<h2 class="hasAnchor">
<a href="#a-simple-model" class="anchor"></a>A simple model</h2>
<p>Okay let’s think about this. Here is the model that we have so far looked at alongside its priors:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># specify priors</span>
<span class="va">priors_simple</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="co"># prior for the Intercept (= the reference level)</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">15</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,
  <span class="co"># prior for the fixed effect coefficient for polite attitude</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">attitudepol</span><span class="op">)</span>,
  <span class="co"># prior for the residual variance</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># specify model</span>
<span class="va">simple_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>
  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span>,  
  data <span class="op">=</span> <span class="va">polite</span>,
  prior <span class="op">=</span> <span class="va">priors_simple</span>,
  family <span class="op">=</span> <span class="va">gaussian</span>
<span class="op">)</span></code></pre></div>
<p>Brms uses a gaussian link function by default (we made that explicit above), i.e. we assume that the model residuals are normally distributed. But is that really the case? We have a measurement that is bound by 0, because there can’t be negative values for articulation rate, right? It is likely that articulate rate data are skewed to the right, because values can vary more toward higher values than toward lower values. Brms allows us to critically evaluate our model fit by comparing the model using so-called posterior predictive checks. Posterior predictive checks are, in simple words, “simulating replicated data under the fitted model and then comparing these to the observed data” (<a href="http://www.stat.columbia.edu/~gelman/arm/">Gelman &amp; Hill 2007: 158</a>). So, you use posterior predictive checks to investigate whether there are systematic discrepancies between the observed and simulated data.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># posterior predictive check</span>
<span class="fu"><a href="https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html">pp_check</a></span><span class="op">(</span><span class="va">simple_model</span>, nsamples <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></code></pre></div>
<p>Looking at the plot, you see a thick dark blue line which is the data, and bunch of light blue lines which are simulated data based on your model. The model assumes a normal distribution, so the posterior draws are much more symmetric than the actual data, thus we notice a discrepancy between model and data. These situations are common for measurements that are bound by zero (e.g. duration or response latency). To account for this, we can use a different link function (specified with the <code>family</code> argument). A more appropriate model would use a log normal distribution for articulation rate.</p>
<p>When we change the family, the model will fit the measurement in log space, so we will have to change the priors. Let’s throw in some numbers and run a prior_predictive check, i.e. running the model with only the prior information (<code>sample_prior = "only"</code>). We also need to specify the <code>lognormal</code> family when running the model.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co"># specify priors in log space</span>
<span class="va">priors_simple_log</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="co"># prior for the Intercept (= the reference level)</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,
  <span class="co"># prior for the fixed effect coefficient for polite attitude</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">attitudepol</span><span class="op">)</span>,
  <span class="co"># prior for the residual variance</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># specify model</span>
<span class="va">simple_model2_prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>
  <span class="va">articulation_rate</span> <span class="op">~</span> 
    <span class="va">attitude</span>,  
    data <span class="op">=</span> <span class="va">polite</span>,
    prior <span class="op">=</span> <span class="va">priors_simple_log</span>,
    <span class="co"># specify that the model should only estimate the posterior based on the information in the prior</span>
    sample_prior <span class="op">=</span> <span class="st">"only"</span>,
    <span class="co"># specify lognormal family function</span>
    family <span class="op">=</span> <span class="va">lognormal</span>
  <span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># quick and dirty plot on the original scale</span>
<span class="fu"><a href="https://rdrr.io/pkg/brms/man/conditional_effects.brmsfit.html">conditional_effects</a></span><span class="op">(</span><span class="va">simple_model2_prior</span><span class="op">)</span></code></pre></div>
<p>Well, our priors are very weakly informative and cover more than what we consider a possible range for articulation rate. However it constraints the parameter space substantially already. Good enough.</p>
<p>Let’s refit the model and specify the <code>lognormal</code> family.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co"># specify model</span>
<span class="va">simple_model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>
  <span class="va">articulation_rate</span> <span class="op">~</span> 
    <span class="va">attitude</span>,  
    data <span class="op">=</span> <span class="va">polite</span>,
    prior <span class="op">=</span> <span class="va">priors_simple_log</span>,
    family <span class="op">=</span> <span class="va">lognormal</span>
  <span class="op">)</span></code></pre></div>
<p>And check the model fit again:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># posterior predictive check</span>
<span class="fu"><a href="https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html">pp_check</a></span><span class="op">(</span><span class="va">simple_model2</span>, nsamples <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></code></pre></div>
<p>Much better, right? So by critically evaluating our model assumptions and the actual data we discovered that a <code>lognormal</code> distribution is a much better assumption about the underlying generative model (i.e. how the data came to be).</p>
<p>Fantastic! Let’s have a look at the results (remember that the results are now log transformed)</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Extract posterior coefficient and plot</span>
<span class="va">simple_model2</span> <span class="op">%&gt;%</span> 
 <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/spread_draws.html">spread_draws</a></span><span class="op">(</span><span class="va">b_attitudepol</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="co"># plot</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_attitudepol</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_sample_slabinterval.html">stat_halfeye</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"log(articulation rate)"</span><span class="op">)</span></code></pre></div>
<p>If you want to plot something more traditional, i.e. the posterior values for polite and informal speech productions, we can use some neat functions from other packages. This way we can plot the data in log space and compare the two conditions immediately.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Extract posterior and plot predicted values for both levels</span>
<span class="va">polite</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://modelr.tidyverse.org/reference/data_grid.html">data_grid</a></span><span class="op">(</span><span class="va">attitude</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/add_predicted_draws.html">add_predicted_draws</a></span><span class="op">(</span><span class="va">simple_model2</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="co"># plot</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">.prediction</span>, y <span class="op">=</span> <span class="va">attitude</span>, fill <span class="op">=</span> <span class="va">attitude</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_sample_slabinterval.html">stat_halfeye</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_fill_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"#8970FF"</span>, <span class="st">"#FFA70B"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"articulation rate"</span><span class="op">)</span></code></pre></div>
</div>
<div id="adding-predictors" class="section level2">
<h2 class="hasAnchor">
<a href="#adding-predictors" class="anchor"></a>Adding predictors</h2>
<p>This model estimates the effect of <code>attitude</code> on articulation rate (<code>articulation_rate</code>). That.is.it. But what if we also want to estimate the differences between attitude across different experimental tasks? Let’s add <code>task</code> as a predictor and add a prior for it as well. Let’s stick to weakly informative priors again, centered on zero (we expect no difference of articulation rate between different tasks and acknowledge the possibility of some variance around that value).</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># get prior</span>
<span class="fu"><a href="https://rdrr.io/pkg/brms/man/get_prior.html">get_prior</a></span><span class="op">(</span>
 formula <span class="op">=</span> <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span>,
  data <span class="op">=</span> <span class="va">polite</span>, family <span class="op">=</span> <span class="va">lognormal</span>
<span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># specify priors</span>
<span class="va">priors_multiple</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">attitudepol</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">tasknot</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># tun model</span>
<span class="va">multiple_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>
  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span>,
  data <span class="op">=</span> <span class="va">polite</span>,
  prior <span class="op">=</span> <span class="va">priors_multiple</span>,
  family <span class="op">=</span> <span class="va">lognormal</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">multiple_model</span><span class="op">)</span></code></pre></div>
<p>Looking at the summary of the model, we get a table with two coefficients for the population parameters <code>attitudepol</code> and <code>tasknot</code>. Let’s remind ourselves that these reflect the change in articulation rate from the reference level (attitude = informal (<code>inf</code>), task = dialog completion task (<code>dct</code>)) to attitude = polite (<code>attitudepol</code>) and to task = note (<code>tasknot</code>), respectively.</p>
<p>We can inspect posteriors for both predictors just like we did before:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Extract posterior coefficient attitudepol</span>
<span class="va">post_multiple_attitude</span> <span class="op">&lt;-</span> <span class="va">multiple_model</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/spread_draws.html">spread_draws</a></span><span class="op">(</span><span class="va">b_attitudepol</span>, <span class="va">b_tasknot</span><span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">post_multiple_attitude</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_sample_slabinterval.html">stat_halfeye</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_attitudepol</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"posterior for effect of attitude"</span>,
         x <span class="op">=</span> <span class="st">"log(articulation rate)"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span>
 
<span class="co"># Extract posterior coefficient tasknot </span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">post_multiple_attitude</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_sample_slabinterval.html">stat_halfeye</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_tasknot</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"posterior for effect of task"</span>,
         x <span class="op">=</span> <span class="st">"log(articulation rate)"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span></code></pre></div>
<p>Both posterior distributions are very clearly located to the left of zero, suggesting that there is both attitude and task affect articulation-rate to some extend (given the model, the data, and the prior assumptions)</p>
</div>
<div id="adding-random-effects" class="section level2">
<h2 class="hasAnchor">
<a href="#adding-random-effects" class="anchor"></a>Adding random effects</h2>
<p>So running Bayesian regression models is really not much different from running frequentist regression models. Practically, the only difference so far is that we specify prior knowledge. Conceptually, we obviously interpret the output differently in terms of the inference we draw, but this should be business as usual for you.</p>
<p>Now, we probably all suspect that this model is not quite appropriate for the data, right? It does not take into account the fact that data points are not independent from each other. There were multiple speakers that produced multiple data points, so observations from these speakers are not independent and we need to take that into account for robust inference. So let’s also add an appropriate random effect structure, including a by-subject random intercept as well as a by-subject random slope for attitude.</p>
<p>We can write down the code to run this model easily, because we should be familiar with the <code>lme4</code> syntax. <code>brms</code> syntax handles random effect structure exactly like <code>lme4</code> like so:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># model specification</span>
<span class="va">complex_model_formula</span> <span class="op">=</span> 
  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span> <span class="op">+</span>
    <span class="co"># add random intercept</span>
    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span> <span class="op">+</span>
    <span class="co"># add random slope</span>
    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">attitude</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span></code></pre></div>
<p>Looks familiar?</p>
<p>But what about priors? Do we need to specify priors for these new elements as well? And if so how?</p>
<p>Generally, we encourage you to specify priors for all elements of your model, so let us try this as well.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># get prior</span>
<span class="fu"><a href="https://rdrr.io/pkg/brms/man/get_prior.html">get_prior</a></span><span class="op">(</span>
  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span> <span class="op">+</span>
    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span> <span class="op">+</span>
    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">attitude</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span>,  
   data <span class="op">=</span> <span class="va">polite</span>,
   family <span class="op">=</span> <span class="va">lognormal</span>
<span class="op">)</span></code></pre></div>
<p>We need to specify four parameters for the Group-Level Effects. Three of them are variance components that we will specify with half-cauchy distributions, just like we did for the residual variance. The final parameter is a correlation coefficient of the group level effects and will be specified using the Lewandowski-Kurowicka-Joe prior (LKJ).</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># specify priors</span>
<span class="va">priors_complex</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">attitudepol</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.25</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span>, coef <span class="op">=</span> <span class="va">tasknot</span><span class="op">)</span>,
  <span class="co"># specify weakly informative prior for the random effects (slopes)</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span>, coef <span class="op">=</span> <span class="va">Intercept</span>, group <span class="op">=</span> <span class="va">subject</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span>, coef <span class="op">=</span> <span class="va">attitudeinf</span>, group <span class="op">=</span> <span class="va">subject</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span>, coef <span class="op">=</span> <span class="va">attitudepol</span>, group <span class="op">=</span> <span class="va">subject</span><span class="op">)</span>,
  <span class="co"># specify weakly informative prior for the correlation between random intercept and slope</span>
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">lkj</span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">cor</span>, group <span class="op">=</span> <span class="va">subject</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/pkg/brms/man/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<p>That is it. Now we can run the model. And we will add one new argument to the <code><a href="https://rdrr.io/pkg/brms/man/brm.html">brm()</a></code> function: The <code>seed</code> argument allows us to set a random seed. The sampling procedure has a random initial state, so if you run this model on your machine, you will get slightly different results from someone else. With <code>seed</code> we can fix this initial state and obtain the exact same results. This is great, because we can make our results fully reproducible that way.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Run model</span>
<span class="va">complex_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>
  <span class="va">articulation_rate</span> <span class="op">~</span> <span class="va">attitude</span> <span class="op">+</span> <span class="va">task</span> <span class="op">+</span>
    <span class="co"># add random intercept</span>
    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span> <span class="op">+</span>
    <span class="co"># add random slope</span>
    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">attitude</span> <span class="op">|</span> <span class="va">subject</span><span class="op">)</span>,  
   data <span class="op">=</span> <span class="va">polite</span>,
   prior <span class="op">=</span> <span class="va">priors_complex</span>,
   family <span class="op">=</span> <span class="va">lognormal</span>,
  <span class="co"># set seed</span>
   seed <span class="op">=</span> <span class="fl">999</span>
<span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">complex_model</span><span class="op">)</span></code></pre></div>
<p>Let us walk through the summary here. We now have one part of the table called “Group-Level Effects”. This part of the table gives us the models estimates for four parameters: How much subjects’ baseline varies (<code><a href="https://rdrr.io/r/stats/sd.html">sd(Intercept)</a></code>), how much they vary in the informal condition (<code><a href="https://rdrr.io/r/stats/sd.html">sd(attitudeinf)</a></code>), how much subjects vary in the polite condition (<code><a href="https://rdrr.io/r/stats/sd.html">sd(attitudepol)</a></code>), and what the correlation between <code><a href="https://rdrr.io/r/stats/sd.html">sd(attitudeinf)</a></code> and <code><a href="https://rdrr.io/r/stats/sd.html">sd(attitudepol)</a></code> is. As before, for all of these parameters, we receive an <code>Estimate</code> which is the mean of the posterior distribution and a range of plausible values within the 95% Credible Interval (<code>l-95% CI</code> - <code>u-95% CI</code>). Except for the correlation, the estimates are bound by 0, i.e. the variance can only be positive. The correlation coefficient can vary between -1 and 1.</p>
<p>The second part of the summary table, i.e. the Population-Level Effects, did not change and summarizes our regression coefficients for the fixed effects. Just like before.</p>
<p>There we go. We have run a linear mixed effects model within the Bayesian framework. We specified priors for both random and fixed effects. What is left is interpreting the output.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Extract posterior coefficient politeness</span>
<span class="va">post_complex</span> <span class="op">&lt;-</span> <span class="va">complex_model</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/spread_draws.html">spread_draws</a></span><span class="op">(</span><span class="va">b_attitudepol</span>, <span class="va">b_tasknot</span><span class="op">)</span> 

<span class="co"># plot</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">post_complex</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_sample_slabinterval.html">stat_halfeye</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">b_attitudepol</span><span class="op">)</span><span class="op">)</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"log(articulation rate)"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span></code></pre></div>
</div>
<div id="making-inference" class="section level2">
<h2 class="hasAnchor">
<a href="#making-inference" class="anchor"></a>Making inference</h2>
<p>Now let’s use these posteriors to draw probability inferences. What is the 95% credible interval for the <code>attitudepol</code> coefficient and what is its probability of direction?</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># extract 95% HDI</span>
<span class="fu"><a href="http://mjskay.github.io/ggdist/reference/point_interval.html">hdi</a></span><span class="op">(</span><span class="va">post_complex</span><span class="op">$</span><span class="va">b_attitudepol</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"\n"</span><span class="op">)</span>
<span class="co"># extract probability of direction</span>
<span class="fu"><a href="https://easystats.github.io/bayestestR/reference/p_direction.html">p_direction</a></span><span class="op">(</span><span class="va">post_complex</span><span class="op">$</span><span class="va">b_attitudepol</span><span class="op">)</span></code></pre></div>
<p>Fantastic! So our best estimate of the effect of attitude has a 95% CrI between [-0.12, -0.01] and a 0.98 probability of being negative. Although the majority of plausible values are negative, positive values are still plausible (given the data, the model, and the priors).</p>
</div>
</div>
<div id="exercise" class="section level1">
<h1 class="hasAnchor">
<a href="#exercise" class="anchor"></a>Exercise</h1>
<p>Now it’s your turn: Our goal is it to run the following model: <code>f0mn ~ attitude + (1 | subject) + (0 + attitude | subject)</code></p>
<ol style="list-style-type: lower-alpha">
<li>First, see which priors we need to specify using the <code><a href="https://rdrr.io/pkg/brms/man/get_prior.html">get_prior()</a></code> function. (If you are unsure, see our code examples above)</li>
</ol>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># get prior</span>
<span class="fu"><a href="https://rdrr.io/pkg/brms/man/get_prior.html">get_prior</a></span><span class="op">(</span>
 formula <span class="op">=</span> <span class="va">...</span>,
 data <span class="op">=</span> <span class="va">...</span>
<span class="op">)</span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Now specify weakly informative priors for all parameters. For the intercept, chose a normal prior with mean = 0 and sd = 500. For simplicity sake, let us just go for normally distributed priors for all other parameters (mean = 0, sd = 100)</li>
</ol>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># specify priors</span>
<span class="va">priors_ex</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="va">...</span>
<span class="op">)</span></code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Now run the model with your specified priors. Use <code>seed = 1111</code> in order for all of you to get the same results.</li>
</ol>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Run model</span>
<span class="va">ex_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span>
  formular <span class="op">=</span> <span class="va">...</span>,
  data <span class="op">=</span> <span class="va">...</span>,
  prior <span class="op">=</span> <span class="va">...</span>,
  seed <span class="op">=</span> <span class="fl">1111</span>
<span class="op">)</span></code></pre></div>
<ol start="4" style="list-style-type: lower-alpha">
<li>Extract the posteriors for the coefficient attitudepol and plot it.</li>
</ol>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Extract posterior coefficient politeness</span>
<span class="va">ex_post</span> <span class="op">&lt;-</span> <span class="va">ex_model</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="http://mjskay.github.io/tidybayes/reference/spread_draws.html">spread_draws</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span>

<span class="co"># plot</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span> <span class="op">+</span>
  <span class="va">...</span></code></pre></div>
<ol start="5" style="list-style-type: lower-alpha">
<li>Now let’s use the posteriors to draw probability inferences. What is the 95% credible interval for the <code>attitudepol</code> coefficient and what is its probability of direction?</li>
</ol>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># extract 95% HDI</span>
<span class="fu"><a href="http://mjskay.github.io/ggdist/reference/point_interval.html">hdi</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span>

<span class="co"># extract probability of direction</span>
<span class="fu"><a href="https://easystats.github.io/bayestestR/reference/p_direction.html">p_direction</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span></code></pre></div>
<ol start="6" style="list-style-type: lower-alpha">
<li>But hold on. Is the model fit okay? Critically check the model fit with <code><a href="https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html">pp_check()</a></code>. Do you think the model and the priors capture the generative process appropriately? What might be the issue? Can you fix it?</li>
</ol>
<p><br></p>
<!-- Solutions -->
<!-- (a) 
get_prior(
 formula = 
   f0mn ~ 
   attitude +
   (1 | subject) + 
   (0 + attitude | subject),
  data = polite
)
-->
<!-- (b) 
priors_ex <- c(
  prior(normal(0, 500), class = Intercept),
  prior(normal(0, 100), class = b, coef = attitudepol),
  # specify weakly informative prior for the random effects (slopes)
  prior(normal(0, 100), class = sd, coef = Intercept, group = subject),
  prior(normal(0, 100), class = sd, coef = attitudeinf, group = subject),
  prior(normal(0, 100), class = sd, coef = attitudepol, group = subject),
  # specify weakly informative prior for the correlation between random intercept and slope
  prior(lkj(2), class = cor, group = subject),
  prior(normal(0, 100), class = sigma)
)
-->
<!-- (c)
ex_model <- brm(
  f0mn ~ 
    attitude +
    (1 | subject) +
    (0 + attitude | subject),  
   data = polite,
   prior = priors_ex,
   seed = 1111,
)
-->
<!-- (d)
ex_post <- ex_model %>%
  spread_draws(b_attitudepol)

ggplot(ex_post) + 
  stat_halfeye(aes(x = b_attitudepol)) +
  labs(x = "fundamental frequency in Hz")
-->
<!-- (e)
hdi(ex_post$b_attitudepol)
p_direction(ex_post$b_attitudepol)
-->
<!-- (f)
pp_check(ex_model, nsamples = 100)

Doesn't capture bimodality well and over estimates the probability of value between 0 and 50.
One reason for this is that f0 is also bound to zero and very low values are virtually impossible.
Again, a lognormal link function is probably more appropriate.

priors_ex_log <- c(
  prior(normal(0, 3), class = Intercept),
  prior(normal(0, 2), class = b, coef = attitudepol),
  # specify weakly informative prior for the random effects (slopes)
  prior(cauchy(0, .1), class = sd, coef = Intercept, group = subject),
  prior(cauchy(0, .1), class = sd, coef = attitudeinf, group = subject),
  prior(cauchy(0, .1), class = sd, coef = attitudepol, group = subject),
  # specify weakly informative prior for the correlation between random intercept and slope
  prior(lkj(2), class = cor, group = subject),
  prior(cauchy(0, .1), class = sigma)
)

Run model for priors only

ex_model_log_priors <- brm(
  f0mn ~ 
    attitude +
    (1 | subject) +
    (0 + attitude | subject),  
   data = polite,
   sample_prior = "only",
   family = lognormal,
   prior = priors_ex_log,
   seed = 1111
)

conditional_effects(ex_model_log_priors)

Run model

ex_model_log <- brm(
  f0mn ~ 
    attitude +
    (1 | subject) +
    (0 + attitude | subject),  
   data = polite,
   family = lognormal,
   prior = priors_ex_log,
   seed = 1111
)

pp_check(ex_model_log, nsamples = 100)

Much better!

-->
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Stefano Coretta, Joseph V. Casillas, Timo Roettger.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
